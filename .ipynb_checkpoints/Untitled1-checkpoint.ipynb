{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50a42b4-2119-40b7-8228-d071a8a97800",
   "metadata": {},
   "source": [
    "# UJIAN AKHIR SEMESTER \n",
    "## TIMESERIES\n",
    "\n",
    "### NAMA : Paul Wijaya Verda Kusuma\n",
    "### NIM  : 215314051\n",
    "\n",
    "### LSTM untuk Klasifikasi Trend Saham Evolutionary Algorithm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f066e11c-c562-4f63-a42f-475ee0456d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Nadam, Adamax\n",
    "\n",
    "from deap import base, creator, tools, algorithms\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e52be25-29bf-47dd-a09a-5bd1b8bc4c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# === STEP 1: Load Data ====\n",
    "# ===========================\n",
    "df = pd.read_csv('usd_idr_processed_data.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Tambah fitur teknikal\n",
    "df['MA5'] = df['Close'].rolling(window=5).mean()\n",
    "df['MA10'] = df['Close'].rolling(window=10).mean()\n",
    "df['ROC5'] = df['Close'].pct_change(periods=5)\n",
    "def calculate_rsi(series, period=14):\n",
    "    delta = series.diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(window=period).mean()\n",
    "    loss = -delta.where(delta < 0, 0).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "df['RSI'] = calculate_rsi(df['Close'])\n",
    "\n",
    "# Drop NA\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Ambil fitur\n",
    "features = ['Close', 'High', 'Low', 'Open', 'MA5', 'MA10', 'ROC5', 'RSI']\n",
    "data = df[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f254ee92-23c6-4d83-ba9e-70401253db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# === STEP 2: Normalisasi ===\n",
    "# ===========================\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e5fd49b-62c2-4995-b0a7-f111cf56095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# === STEP 3: Dataset ===\n",
    "# ===========================\n",
    "def generate_dataset(data_scaled, window_size=20, threshold=0.0035):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data_scaled) - window_size - 1):\n",
    "        X.append(data_scaled[i:i + window_size])\n",
    "        diff = data_scaled[i + window_size][0] - data_scaled[i + window_size - 1][0]\n",
    "        if diff > threshold:\n",
    "            label = [0, 0, 1]  # Naik\n",
    "        elif diff < -threshold:\n",
    "            label = [1, 0, 0]  # Turun\n",
    "        else:\n",
    "            label = [0, 1, 0]  # Stasioner\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def split_dataset(X, y, ratio=0.8):\n",
    "    split = int(len(X) * ratio)\n",
    "    return X[:split], X[split:], y[:split], y[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7f1d984-7e79-4d8b-90df-40bc4d67a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# === STEP 4: Model Creator ===\n",
    "# ================================\n",
    "def create_model(units, optimizer_name, lr, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(LSTM(units, return_sequences=True, activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units // 2, activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.get(optimizer_name)\n",
    "    optimizer.learning_rate = lr\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "433c8d8a-1973-4b24-b281-a75b45730651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weight(y_train):\n",
    "    y_int = np.argmax(y_train, axis=1)\n",
    "    weights = compute_class_weight(class_weight='balanced',\n",
    "                                   classes=np.unique(y_int),\n",
    "                                   y=y_int)\n",
    "    return dict(enumerate(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "131fead2-80ca-4fd5-837f-94fc420b4d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# === STEP 5: Genetic Fitness ===\n",
    "# ================================\n",
    "def eval_fitness(ind, X_train, y_train, X_test, y_test, window_size):\n",
    "    units = int(ind[0])\n",
    "    opt_idx = int(round(ind[1]))\n",
    "    lr_exp = ind[2]\n",
    "    epochs = int(ind[3])\n",
    "\n",
    "    # Clamp optimizer index to valid range\n",
    "    opt_idx = max(0, min(3, opt_idx))\n",
    "    opt_name = ['adam', 'rmsprop', 'nadam', 'adamax'][opt_idx % 4]\n",
    "    lr = 10 ** (-lr_exp)\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "    model = create_model(units, opt_name, lr, input_shape)\n",
    "    \n",
    "    class_weight = get_class_weight(y_train)\n",
    "\n",
    "    early = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=16, verbose=0,\n",
    "              validation_data=(X_test, y_test), callbacks=[early], class_weight=class_weight)\n",
    "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    # Kembalikan model untuk disimpan nanti\n",
    "    return acc, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fe4ddf2-2721-4d27-ab3f-feb13148064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# === STEP 6: Setup GA Toolbox ===\n",
    "# ================================\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_units\", lambda: random.randint(50, 150))\n",
    "toolbox.register(\"attr_opt\", lambda: random.randint(0, 3))  # 0 = adam, 1 = rmsprop\n",
    "toolbox.register(\"attr_lr\", lambda: random.uniform(2, 4))   # exponent\n",
    "toolbox.register(\"attr_epochs\", lambda: random.randint(10, 50))\n",
    "\n",
    "toolbox.register(\n",
    "    \"individual\",\n",
    "    tools.initCycle,\n",
    "    creator.Individual,\n",
    "    (toolbox.attr_units, toolbox.attr_opt, toolbox.attr_lr, toolbox.attr_epochs),\n",
    "    n=1,\n",
    ")\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd62fa35-79a2-4ec0-8d50-0a8984f369da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# === Custom Mutate Function ===\n",
    "# ================================\n",
    "def custom_mutate(ind):\n",
    "    if random.random() < 0.2:\n",
    "        ind[0] = int(np.clip(ind[0] + random.gauss(0, 5), 32, 128))\n",
    "    if random.random() < 0.2:\n",
    "        ind[1] = 1 - int(ind[1])  # Toggle optimizer\n",
    "    if random.random() < 0.2:\n",
    "        ind[2] = np.clip(ind[2] + random.gauss(0, 0.3), 2, 4)\n",
    "    if random.random() < 0.2:\n",
    "        ind[3] = int(np.clip(ind[3] + random.gauss(0, 2), 5, 20))\n",
    "    return ind,\n",
    "\n",
    "toolbox.register(\"mutate\", custom_mutate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e7f5cb-8451-4a00-8ac0-62f921a94b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# === STEP 6: GA + Window Loop ===\n",
    "# ================================\n",
    "window_sizes = [10, 20, 30, 40, 50, 60, 70]\n",
    "results = []\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    X, y = generate_dataset(data_scaled, window_size)\n",
    "    X_train, X_test, y_train, y_test = split_dataset(X, y)\n",
    "\n",
    "    # Register fresh fitness function\n",
    "    if \"evaluate\" in toolbox.__dict__:\n",
    "        del toolbox.evaluate\n",
    "\n",
    "    def fitness_wrapper(ind):\n",
    "        acc, model = eval_fitness(ind, X_train, y_train, X_test, y_test, window_size)\n",
    "        ind.model = model  # Simpan model dalam individu\n",
    "        return (acc,)\n",
    "\n",
    "    toolbox.register(\"evaluate\", fitness_wrapper)\n",
    "\n",
    "    pop = toolbox.population(n=20)\n",
    "    NGEN = 10\n",
    "\n",
    "    for gen in range(NGEN):\n",
    "        offspring = algorithms.varAnd(pop, toolbox, cxpb=0.5, mutpb=0.2)\n",
    "        fits = list(map(toolbox.evaluate, offspring))\n",
    "        for fit, ind in zip(fits, offspring):\n",
    "            ind.fitness.values = fit\n",
    "        pop = toolbox.select(offspring, k=len(pop))\n",
    "\n",
    "    best = tools.selBest(pop, k=1)[0]\n",
    "    units, opt_idx, lr_exp, epochs = best\n",
    "    opt_name = ['adam', 'rmsprop', 'nadam', 'adamax'][int(round(opt_idx))]\n",
    "    lr = 10 ** (-lr_exp)\n",
    "    acc = best.fitness.values[0]\n",
    "\n",
    "    results.append((window_size, acc, units, opt_name, lr, int(epochs), best.model))\n",
    "    print(f\"Window: {window_size}, Akurasi: {acc:.4f}, Units: {units}, Opt: {opt_name}, \"\n",
    "          f\"LR: {lr:.5f}, Epochs: {int(epochs)}\")\n",
    "\n",
    "    #evaluasi klasifikasi\n",
    "    y_pred = best.model.predict(X_test)\n",
    "    y_pred_class = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    print(classification_report(y_true, y_pred_class, target_names=['Turun', 'Stasioner', 'Naik']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80262e5-1242-44fa-a76c-ee40557df779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# === STEP 7: Save Model & Scaler\n",
    "# ================================\n",
    "import joblib\n",
    "\n",
    "best_result = max(results, key=lambda x: x[1])\n",
    "window_size, acc, units, opt_name, lr, epochs, best_model = best_result\n",
    "\n",
    "# Simpan model ke format baru\n",
    "best_model.save(\"model_lstm_tren_terbaik.keras\")\n",
    "\n",
    "# Simpan scaler\n",
    "joblib.dump(scaler, \"scaler_lstm_tren.save\")\n",
    "\n",
    "print(\"Model dan Scaler berhasil disimpan.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5789ef2-6454-41c6-a1d1-d87d8c873c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# === STEP 8: Prediksi Data Baru\n",
    "# ================================\n",
    "last_window = data_scaled[-window_size:]\n",
    "last_window = np.expand_dims(last_window, axis=0)\n",
    "pred = best_model.predict(last_window)\n",
    "predicted_class = np.argmax(pred)\n",
    "\n",
    "label_map = {0: 'Turun', 1: 'Stasioner', 2: 'Naik'}\n",
    "print(\"Prediksi tren data terbaru:\", label_map[predicted_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea326e-c579-45ab-afa9-387b8de26fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil data asli\n",
    "close_t = df[\"Close\"].iloc[-2]\n",
    "close_t_plus_1 = df[\"Close\"].iloc[-1]\n",
    "delta = (close_t_plus_1 - close_t) / close_t  # Persentase perubahan\n",
    "\n",
    "# Ubah ke label\n",
    "if delta > 0.002:\n",
    "    actual_class = 2  # Naik\n",
    "elif delta < -0.002:\n",
    "    actual_class = 0  # Turun\n",
    "else:\n",
    "    actual_class = 1  # Stasioner\n",
    "\n",
    "print(\"Label aktual:\", label_map[actual_class])\n",
    "print(\"Prediksi benar?\" , actual_class == predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b694cf9-e58a-4206-a724-f9ce330d1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Buat dataset untuk seluruh data\n",
    "X_all, y_all = generate_dataset(data_scaled, window_size=20)\n",
    "\n",
    "# Ambil label-nya\n",
    "y_labels = np.argmax(y_all, axis=1)\n",
    "\n",
    "# Hitung jumlah masing-masing label\n",
    "label_counts = Counter(y_labels)\n",
    "label_map = {0: 'Turun', 1: 'Stasioner', 2: 'Naik'}\n",
    "\n",
    "# Tampilkan hasil dalam angka\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label_map[label]}: {count} data\")\n",
    "\n",
    "# Visualisasi histogram\n",
    "plt.hist(y_labels, bins=np.arange(4)-0.5, edgecolor='black')\n",
    "plt.xticks([0, 1, 2], ['Turun', 'Stasioner', 'Naik'])\n",
    "plt.title('Distribusi Label')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Jumlah')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f98c2-f53b-4b1a-af16-8615a2098448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# === Ringkasan Hasil Terbaik ===\n",
    "# ================================\n",
    "print(\"\\n=== Ringkasan Hasil Terbaik ===\")\n",
    "print(f\"Window Size Optimal: {window_size}\")\n",
    "print(f\"Akurasi Tertinggi: {acc:.4f}\")\n",
    "print(f\"Units: {units}, Optimizer: {opt_name}, Learning Rate: {lr:.5f}, Epochs: {epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7142af60-e02a-42c1-910c-cf5d804df2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
