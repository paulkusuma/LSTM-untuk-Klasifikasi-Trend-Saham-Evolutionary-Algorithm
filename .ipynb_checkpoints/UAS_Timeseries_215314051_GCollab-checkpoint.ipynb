{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7czAp5wjIjYT"
      },
      "source": [
        "# UJIAN AKHIR SEMESTER\n",
        "## TIMESERIES\n",
        "\n",
        "### NAMA : Paul Wijaya Verda Kusuma\n",
        "### NIM  : 215314051\n",
        "\n",
        "### LSTM untuk Klasifikasi Trend Saham Evolutionary Algorithm`\n",
        "### BTC-USD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dBUHWctbIivZ",
        "outputId": "5c2b885c-c436-45a1-f345-6d40d7722cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "Requirement already satisfied: deap in /usr/local/lib/python3.11/dist-packages (1.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas scikit-learn tensorflow joblib deap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7IGIUmMYkL33"
      },
      "outputs": [],
      "source": [
        "# === [1] STABILITAS & REPRODUCIBILITY ===\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IdcIdKxOITg5"
      },
      "outputs": [],
      "source": [
        "# === Library Setup ===\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from deap import base, creator, tools, algorithms\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgs6ly_XITSL",
        "outputId": "93860268-26ab-4746-d4b3-63491f711fa9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler_btc_usd.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# === [3] LOAD DATA ===\n",
        "df = pd.read_csv('/content/sample_data/BTC-USD_processed_data.csv', index_col='Date', parse_dates=True)\n",
        "\n",
        "# === Fitur Teknikal Tambahan ===\n",
        "df['MA5'] = df['Close'].rolling(window=5).mean()\n",
        "df['MA10'] = df['Close'].rolling(window=10).mean()\n",
        "df['ROC5'] = df['Close'].pct_change(periods=5)\n",
        "\n",
        "def calculate_rsi(series, period=14):\n",
        "    delta = series.diff()\n",
        "    gain = delta.where(delta > 0, 0).rolling(window=period).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(window=period).mean()\n",
        "    rs = gain / loss\n",
        "    return 100 - (100 / (1 + rs))\n",
        "\n",
        "df['RSI'] = calculate_rsi(df['Close'])\n",
        "df['EMA10'] = df['Close'].ewm(span=10, adjust=False).mean()\n",
        "df['BB_MA'] = df['Close'].rolling(window=20).mean()\n",
        "df['BB_STD'] = df['Close'].rolling(window=20).std()\n",
        "df['BB_Upper'] = df['BB_MA'] + 2 * df['BB_STD']\n",
        "df['BB_Lower'] = df['BB_MA'] - 2 * df['BB_STD']\n",
        "ema12 = df['Close'].ewm(span=12, adjust=False).mean()\n",
        "ema26 = df['Close'].ewm(span=26, adjust=False).mean()\n",
        "df['MACD'] = ema12 - ema26\n",
        "df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "df['H-L'] = df['High'] - df['Low']\n",
        "df['H-PC'] = abs(df['High'] - df['Close'].shift(1))\n",
        "df['L-PC'] = abs(df['Low'] - df['Close'].shift(1))\n",
        "df['TR'] = df[['H-L', 'H-PC', 'L-PC']].max(axis=1)\n",
        "df['ATR'] = df['TR'].rolling(window=14).mean()\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# === [5] SCALING ===\n",
        "features = [\n",
        "    'Close', 'High', 'Low', 'Open', 'MA5', 'MA10', 'ROC5', 'RSI',\n",
        "    'EMA10', 'BB_Upper', 'BB_Lower', 'MACD', 'MACD_Signal', 'ATR'\n",
        "]\n",
        "data = df[features]\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "joblib.dump(scaler, 'scaler_btc_usd.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C6xVKGsUI3j5"
      },
      "outputs": [],
      "source": [
        "def generate_dataset(data_scaled, window_size):\n",
        "\n",
        "    X, y = [], []\n",
        "    close_prices = scaler.inverse_transform(data_scaled)[:, 0]\n",
        "    log_returns = np.log(close_prices[1:] / close_prices[:-1])\n",
        "\n",
        "    # Hitung threshold log return kuantil & batasi minimum perubahan signifikan\n",
        "    up_thresh = np.quantile(log_returns, 0.70)\n",
        "    down_thresh = np.quantile(log_returns, 0.30)\n",
        "\n",
        "    for i in range(len(data_scaled) - window_size - 1):\n",
        "        X.append(data_scaled[i:i + window_size])\n",
        "        prev_close = close_prices[i + window_size - 1]\n",
        "        next_close = close_prices[i + window_size]\n",
        "        log_ret = np.log(next_close / prev_close)\n",
        "\n",
        "        if log_ret > up_thresh:\n",
        "            label = [0, 0, 1]  # Naik\n",
        "        elif log_ret < down_thresh:\n",
        "            label = [1, 0, 0]  # Turun\n",
        "        else:\n",
        "            label = [0, 1, 0]  # Stasioner\n",
        "        y.append(label)\n",
        "\n",
        "    # Untuk debugging: lihat distribusi kelas\n",
        "    label_counts = np.sum(y, axis=0)\n",
        "    print(f\"Distribusi Label (Turun, Stasioner, Naik): {label_counts}\")\n",
        "\n",
        "    return np.array(X), np.array(y), up_thresh, down_thresh\n",
        "\n",
        "def split_dataset(X, y, ratio=0.8):\n",
        "    split = int(len(X) * ratio)\n",
        "    return X[:split], X[split:], y[:split], y[split:]\n",
        "\n",
        "def get_class_weight(y):\n",
        "    y_int = np.argmax(y, axis=1)\n",
        "    classes = np.unique(y_int)\n",
        "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_int)\n",
        "    return dict(zip(classes, weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AHdqEKvAI7k5"
      },
      "outputs": [],
      "source": [
        "# === [7] MODEL LSTM ===\n",
        "def create_model(units, optimizer_name, lr, input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(units, return_sequences=True),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        LSTM(units // 2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "    optimizer = tf.keras.optimizers.get(optimizer_name)\n",
        "    optimizer.learning_rate = lr\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ou86N32xJAOA"
      },
      "outputs": [],
      "source": [
        "# === [8] GA: VARIABEL GLOBAL & EVALUATOR ===\n",
        "global_X_train, global_X_test = None, None\n",
        "global_y_train, global_y_test = None, None\n",
        "global_input_shape = None\n",
        "\n",
        "def eval_fitness(ind):\n",
        "    global global_X_train, global_X_test, global_y_train, global_y_test, global_input_shape\n",
        "\n",
        "    units = max(16, int(ind[0]))\n",
        "    opt_idx = int(round(ind[1])) % 4\n",
        "    lr_exp = max(2.5, min(5.0, ind[2]))\n",
        "    epochs = max(5, int(ind[3]))\n",
        "\n",
        "    optimizer = ['adam', 'rmsprop', 'nadam', 'adamax'][opt_idx]\n",
        "    lr = 10 ** (-lr_exp)\n",
        "\n",
        "    # Pakai input_shape global\n",
        "    model = create_model(units, optimizer, lr, global_input_shape)\n",
        "    class_weight = get_class_weight(global_y_train)\n",
        "    early = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "    model.fit(global_X_train, global_y_train, epochs=epochs, batch_size=32, verbose=0,\n",
        "              validation_data=(global_X_test, global_y_test), callbacks=[early],\n",
        "              class_weight=class_weight)\n",
        "\n",
        "    _, acc = model.evaluate(global_X_test, global_y_test, verbose=0)\n",
        "    ind.model = model\n",
        "    return (acc,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KPQypcYJJDVA"
      },
      "outputs": [],
      "source": [
        "# === [9] INISIALISASI DEAP ===\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"units\", random.randint, 32, 128)\n",
        "toolbox.register(\"opt_idx\", random.randint, 0, 3)\n",
        "toolbox.register(\"lr_exp\", random.uniform, 2.5, 4.5)\n",
        "toolbox.register(\"epochs\", random.randint, 5, 30)\n",
        "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "                 (toolbox.units, toolbox.opt_idx, toolbox.lr_exp, toolbox.epochs), n=1)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
        "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1.0, indpb=0.2)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "toolbox.register(\"evaluate\", eval_fitness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOndaFeslU30",
        "outputId": "88e4ea2c-4547-41f5-c57d-dbe637a2eb29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Evaluating Window Size: 10 ===\n",
            "Distribusi Label (Turun, Stasioner, Naik): [1148 1529 1142]\n"
          ]
        }
      ],
      "source": [
        " #=== [10] LOOP WINDOW SIZE ===\n",
        "results = []\n",
        "window_sizes = [10, 20, 30, 40]\n",
        "\n",
        "for window_size in window_sizes:\n",
        "    print(f\"\\n=== Evaluating Window Size: {window_size} ===\")\n",
        "    X, y, up_thresh, down_thresh = generate_dataset(data_scaled, window_size)\n",
        "    X_train, X_test, y_train, y_test = split_dataset(X, y)\n",
        "\n",
        "    global_X_train, global_X_test = X_train, X_test\n",
        "    global_y_train, global_y_test = y_train, y_test\n",
        "    global_input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "    pop = toolbox.population(n=7)\n",
        "    hof = tools.HallOfFame(1)\n",
        "    algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=3, stats=None, halloffame=hof, verbose=True)\n",
        "\n",
        "    best_ind = hof[0]\n",
        "    best_model = best_ind.model\n",
        "    acc = best_ind.fitness.values[0]\n",
        "\n",
        "    results.append((window_size, acc, best_ind, best_model, up_thresh, down_thresh))\n",
        "\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    y_pred_class = np.argmax(y_pred, axis=1)\n",
        "    y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "    print(classification_report(y_true, y_pred_class, target_names=['Turun', 'Stasioner', 'Naik']))\n",
        "    cm = confusion_matrix(y_true, y_pred_class)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Turun', 'Stasioner', 'Naik'],\n",
        "                yticklabels=['Turun', 'Stasioner', 'Naik'])\n",
        "    plt.title(f\"Confusion Matrix (Window Size: {window_size})\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ze2n7MllYep"
      },
      "outputs": [],
      "source": [
        "# === [11] SIMPAN MODEL TERBAIK ===\n",
        "best_result = max(results, key=lambda x: x[1])\n",
        "best_window, best_acc, best_ind, best_model, best_up, best_down = best_result\n",
        "filename = f\"best_model_BTC_ws{best_window}.h5\"\n",
        "best_model.save(filename)\n",
        "print(f\"\\nBest Window Size: {best_window}, Accuracy: {best_acc:.4f}\")\n",
        "print(f\"Best Threshold Naik: {best_up:.6f}\")\n",
        "print(f\"Best Threshold Turun: {best_down:.6f}\")\n",
        "print(f\"Model saved as: {filename}\")\n",
        "\n",
        "# === Cetak Arsitektur Terbaik ===\n",
        "units, opt_idx, lr_exp, epochs = best_ind\n",
        "optimizers = ['adam', 'rmsprop', 'nadam', 'adamax']\n",
        "optimizer = optimizers[int(round(opt_idx)) % len(optimizers)]\n",
        "lr = 10 ** (-lr_exp)\n",
        "\n",
        "print(\"\\n=== Arsitektur Terbaik ===\")\n",
        "print(f\"Units LSTM         : {int(units)}\")\n",
        "print(f\"Optimizer          : {optimizer}\")\n",
        "print(f\"Learning Rate      : {lr:.6f}\")\n",
        "print(f\"Epochs             : {int(epochs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqfyBWk6ldxM"
      },
      "outputs": [],
      "source": [
        "# === [12] VISUALISASI AKURASI PER WINDOW ===\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot([r[0] for r in results], [r[1] for r in results], marker='o', linestyle='-', color='purple')\n",
        "plt.title(\"Akurasi per Window Size\")\n",
        "plt.xlabel(\"Window Size\")\n",
        "plt.ylabel(\"Akurasi\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqVfMcp6JSHh"
      },
      "outputs": [],
      "source": [
        "# === STEP 8: Prediksi Pergerakan Berikutnya ===\n",
        "print(\"\\n=== Prediksi Pergerakan Berikutnya ===\")\n",
        "\n",
        "# Ambil window terakhir dari data untuk prediksi\n",
        "latest_sequence = data_scaled[-best_window:]  # best_window berasal dari hasil terbaik\n",
        "latest_sequence = np.expand_dims(latest_sequence, axis=0)  # Sesuaikan dimensi untuk LSTM\n",
        "\n",
        "# Prediksi\n",
        "prediction = best_model.predict(latest_sequence)\n",
        "predicted_class = np.argmax(prediction)\n",
        "confidence = np.max(prediction)\n",
        "\n",
        "# Mapping kelas\n",
        "class_mapping = {0: 'Turun', 1: 'Stasioner', 2: 'Naik'}\n",
        "predicted_label = class_mapping[predicted_class]\n",
        "\n",
        "print(f\"Prediksi Pergerakan Berikutnya: {predicted_label} (Probabilitas: {confidence:.2f})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2R8__JrS-2MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === PREDIKSI DATASET BARU ===\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# === Load model & scaler yang sudah disimpan ===\n",
        "model = load_model(filename)\n",
        "scaler = joblib.load('scaler_btc_usd.pkl')\n",
        "\n",
        "# === Load dan proses dataset baru ===\n",
        "new_df = pd.read_csv('/content/sample_data/ETH-USD_processed_data.csv', index_col='Date', parse_dates=True)\n",
        "\n",
        "# === Tambahkan fitur teknikal yang sama ===\n",
        "new_df['MA5'] = new_df['Close'].rolling(window=5).mean()\n",
        "new_df['MA10'] = new_df['Close'].rolling(window=10).mean()\n",
        "new_df['ROC5'] = new_df['Close'].pct_change(periods=5)\n",
        "new_df['RSI'] = calculate_rsi(new_df['Close'])\n",
        "new_df['EMA10'] = new_df['Close'].ewm(span=10, adjust=False).mean()\n",
        "new_df['BB_MA'] = new_df['Close'].rolling(window=20).mean()\n",
        "new_df['BB_STD'] = new_df['Close'].rolling(window=20).std()\n",
        "new_df['BB_Upper'] = new_df['BB_MA'] + 2 * new_df['BB_STD']\n",
        "new_df['BB_Lower'] = new_df['BB_MA'] - 2 * new_df['BB_STD']\n",
        "ema12_new = new_df['Close'].ewm(span=12, adjust=False).mean()\n",
        "ema26_new = new_df['Close'].ewm(span=26, adjust=False).mean()\n",
        "new_df['MACD'] = ema12_new - ema26_new\n",
        "new_df['MACD_Signal'] = new_df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "new_df['H-L'] = new_df['High'] - new_df['Low']\n",
        "new_df['H-PC'] = abs(new_df['High'] - new_df['Close'].shift(1))\n",
        "new_df['L-PC'] = abs(new_df['Low'] - new_df['Close'].shift(1))\n",
        "new_df['TR'] = new_df[['H-L', 'H-PC', 'L-PC']].max(axis=1)\n",
        "new_df['ATR'] = new_df['TR'].rolling(window=14).mean()\n",
        "\n",
        "new_df.dropna(inplace=True)\n",
        "\n",
        "# === Ambil fitur & scaling ===\n",
        "new_data = new_df[features]\n",
        "new_data_scaled = scaler.transform(new_data)\n",
        "\n",
        "# === Ambil window terakhir dari dataset baru untuk prediksi ===\n",
        "if len(new_data_scaled) >= best_window:\n",
        "    latest_input = new_data_scaled[-best_window:]\n",
        "    latest_input = np.expand_dims(latest_input, axis=0)  # shape: (1, window, features)\n",
        "\n",
        "    # === Prediksi ===\n",
        "    pred_prob = model.predict(latest_input)\n",
        "    pred_class = np.argmax(pred_prob, axis=1)[0]\n",
        "    class_labels = ['Turun', 'Stasioner', 'Naik']\n",
        "    confidence = pred_prob[0][pred_class]\n",
        "\n",
        "    # === Tampilkan hasil ===\n",
        "    print(\"\\n=== Prediksi Dataset Baru (1 langkah ke depan) ===\")\n",
        "    print(f\"Arah Prediksi       : {class_labels[pred_class]}\")\n",
        "    print(f\"Probabilitas        : Turun={pred_prob[0][0]:.4f}, Stasioner={pred_prob[0][1]:.4f}, Naik={pred_prob[0][2]:.4f}\")\n",
        "    print(f\"Confidence          : {confidence:.4f}\")\n",
        "else:\n",
        "    print(\"Dataset baru tidak cukup panjang untuk window size ini.\")"
      ],
      "metadata": {
        "id": "ukVQ9eVA-dX_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}